{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c97a24e1-0c31-4057-afc9-4a3c9dabde6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import LlamaForCausalLM, AutoTokenizer\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "\n",
    "device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab539a80-3bce-4c73-af9b-2a7af6038e1a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3a9403a43a34c7c80dcdd44fff2ee8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "llama_dir = '/mntcephfs/data/ruoyusun/liziniu/.cache/huggingface/hub/models--meta-llama--Llama-2-7b-hf/snapshots/8a0442e81540efaeb1a0fe3e95477b5e0edfd423'\n",
    "llama = LlamaForCausalLM.from_pretrained(llama_dir,attn_implementation=\"eager\")\n",
    "llama = llama.to(device) \n",
    "max_positions = 4096\n",
    "attn_bias = torch.tril(torch.ones((max_positions, max_positions), dtype=torch.bool)).view(\n",
    "                1, 1, max_positions, max_positions\n",
    "            )\n",
    "attn_bias = attn_bias.to(device)\n",
    "def attention_score_wo_rotary(layer_idx, hidden_states, num_heads=32, head_dim = 128):\n",
    "    hidden_states = hidden_states.to(device)\n",
    "    bsz, q_len, _ = hidden_states.size()\n",
    "    \n",
    "    attn_model = llama.model.layers[layer_idx]\n",
    "    \n",
    "    layer_norm = attn_model.input_layernorm\n",
    "    \n",
    "    hidden_states = layer_norm(hidden_states)\n",
    "    \n",
    "    query_states = attn_model.self_attn.q_proj(hidden_states)\n",
    "    key_states = attn_model.self_attn.k_proj(hidden_states)\n",
    "    value_states = attn_model.self_attn.v_proj(hidden_states)\n",
    "    \n",
    "    query_states = query_states.view(bsz, q_len, num_heads, head_dim).transpose(1, 2)\n",
    "    key_states = key_states.view(bsz, q_len, num_heads, head_dim).transpose(1, 2)\n",
    "    value_states = value_states.view(bsz, q_len, num_heads,head_dim).transpose(1, 2)\n",
    "    \n",
    "    attn_weights = torch.matmul(query_states, key_states.transpose(2, 3)) / math.sqrt(head_dim)\n",
    "    attn_shape = attn_weights.shape\n",
    "    \n",
    "    query_length, key_length = attn_shape[-2],attn_shape[-1]\n",
    "    causal_mask = attn_bias[:, :, key_length - query_length : key_length, :key_length]\n",
    "    mask_value = torch.finfo(attn_weights.dtype).min\n",
    "    mask_value = torch.full([], mask_value, dtype=attn_weights.dtype, device=attn_weights.device)\n",
    "    attn_weights = torch.where(causal_mask, attn_weights.to(attn_weights.dtype), mask_value)\n",
    "    return attn_weights[0]\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(llama_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "97bd41dc-62f1-47c2-baca-58fc0e0e843f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter(query3_number, M = 10, layer_idx = 0, head_idx = 0, candidate_token_list = torch.arange(llama.vocab_size)): #找出query_token最相近的M个token\n",
    "    token_list = {}\n",
    "    m = 0\n",
    "    while len(token_list)<M:\n",
    "        if m != query3_number:\n",
    "            input_ids = torch.tensor([[query3_number, m]]).long().to(device)\n",
    "            h_s = llama(input_ids,output_hidden_states = True, \n",
    "                        position_ids = torch.ones_like(input_ids).long()).hidden_states[layer_idx] # type: ignore\n",
    "            attention_score = attention_score_wo_rotary(layer_idx=layer_idx, hidden_states=h_s)[head_idx][1,0] #torch.tensor, deivce = 'cuda'\n",
    "            token_list[attention_score] = m\n",
    "        m+=1\n",
    "    score_list = list(token_list.keys())\n",
    "    minimum = min(score_list)\n",
    "    for m in tqdm(candidate_token_list):\n",
    "        if m != query3_number:\n",
    "            input_ids = torch.tensor([[query3_number, m]]).long().to(device)\n",
    "            h_s = llama(input_ids,output_hidden_states = True, \n",
    "                        position_ids = torch.ones_like(input_ids).long()).hidden_states[layer_idx] # type: ignore\n",
    "            attention_score = attention_score_wo_rotary(layer_idx=layer_idx, hidden_states=h_s)[head_idx][1,0]\n",
    "            if attention_score > minimum:\n",
    "                del token_list[minimum]\n",
    "                token_list[attention_score] = m\n",
    "                score_list = list(token_list.keys())\n",
    "                minimum = min(score_list)\n",
    "    return token_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "775e9f72-c6e3-4ca2-956f-284de16829b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing(N = 10, M = 10, inputs = None,layer_idx = 0, head_idx = 0, threshold = 1.0, candidate_strategy = 'all', candidate_num = 1000): #做N次实验, 每次实验选topM\n",
    "    compare_list = {}\n",
    "    word_list = {}\n",
    "    n = 0\n",
    "    while n < N:\n",
    "        #先抽取llama的hidden_states\n",
    "        if inputs == None:\n",
    "            inputs = torch.randint(0,32000,(1,3)).long().to(device)\n",
    "        position_ids = torch.ones_like(inputs).long().to(device)\n",
    "        outputs = llama(inputs,output_hidden_states = True, position_ids = position_ids) # type: ignore\n",
    "        hidden_inputs = outputs.hidden_states[layer_idx]\n",
    "        attention_score = attention_score_wo_rotary(layer_idx, hidden_states=hidden_inputs)[head_idx]\n",
    "        \n",
    "        if abs(attention_score[-1,0]-attention_score[-1,1]) > threshold: #存在某个key比另外一个有明显的强势\n",
    "            word_list[n] = inputs\n",
    "            query3_number = int(inputs[:,-1])\n",
    "            if candidate_strategy == 'all':\n",
    "                candidate_token_list = list(range(llama.vocab_size))\n",
    "            elif candidate_strategy == 'random':\n",
    "                candidate_token_list = random.sample(range(llama.vocab_size),candidate_num)\n",
    "            top_token_list = filter(query3_number,\n",
    "                                    M, layer_idx, head_idx,candidate_token_list=candidate_token_list)#和query3最接近的几个token\n",
    "            compare = []\n",
    "            token1,token2 = inputs[:,0], inputs[:,1]\n",
    "            for token in top_token_list.values():\n",
    "                input_new = torch.tensor([[token1, token2, token]]).to(device)\n",
    "                out_new = llama(input_new, output_hidden_states = True, position_ids = torch.ones_like(input_new).long()) # type: ignore\n",
    "                h_s = out_new.hidden_states[layer_idx]\n",
    "                attention_new = attention_score_wo_rotary(layer_idx, \n",
    "                                                hidden_states=h_s)[head_idx]\n",
    "                compare.append(1 if (attention_new[-1,0]-attention_new[-1,1])*(attention_score[-1,0]-attention_score[-1,1]) >=0 else 0)\n",
    "            compare_list[n] = compare\n",
    "            n+=1\n",
    "    return compare_list, word_list\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "97c7086d-a312-472d-997b-6ffc3111782a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 32000/32000 [18:58<00:00, 28.12it/s]\n"
     ]
    }
   ],
   "source": [
    "candidate_token_list = random.sample(range(32000),5000)\n",
    "inputs = torch.tensor([[   78, 27557, 15044]], device='cuda:0')\n",
    "out = testing(N = 1,candidate_strategy = 'all', candidate_num = 5000, inputs = inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "3a2072c6-9a9a-466c-a94c-62321c28d49c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.9971e-07, -3.4028e+38, -3.4028e+38],\n",
       "        [ 1.7915e-04, -1.0058e+00, -3.4028e+38],\n",
       "        [ 3.4570e-04, -1.5929e+00,  1.5746e-01]], device='cuda:0',\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "position_ids = torch.zeros_like(inputs).reshape(1,-1).long()\n",
    "outputs = llama(inputs,output_hidden_states = True, position_ids = position_ids).hidden_states[0]\n",
    "attention_score_wo_rotary(layer_idx=0, hidden_states=outputs)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "3129ef02-8852-4e32-8180-089af07d510b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.9971e-07, -3.4028e+38, -3.4028e+38],\n",
       "        [ 1.7915e-04, -1.0058e+00, -3.4028e+38],\n",
       "        [-2.9971e-07,  6.6722e-04, -2.9971e-07]], device='cuda:0',\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_inputs = torch.tensor([[   78, 27557, 78]], device='cuda:0')\n",
    "test_outputs = llama(test_inputs,output_hidden_states = True, position_ids = position_ids).hidden_states[0]\n",
    "attention_score_wo_rotary(layer_idx=0, hidden_states=test_outputs)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "2ad6049d-7651-45c5-bc36-ba2329a20902",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       " 1: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       " 2: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       " 3: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       " 4: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       " 5: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       " 6: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " 7: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       " 8: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       " 9: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       " 10: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " 11: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " 12: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       " 13: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       " 14: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       " 15: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       " 16: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       " 17: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       " 18: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " 19: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       " 20: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       " 21: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       " 22: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       " 23: [0, 1, 1, 1, 1, 0, 0, 0, 0, 1],\n",
       " 24: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       " 25: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       " 26: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " 27: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       " 28: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " 29: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load('out.npy',allow_pickle=True)[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
