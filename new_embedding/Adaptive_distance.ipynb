{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "from typing import Any, Dict, List, Optional, Tuple\n",
    "from transformers.cache_utils import Cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_fun(value):\n",
    "    #初步先定为sigmoid函数\n",
    "    return torch.sigmoid(value)\n",
    "    \n",
    "    \n",
    "def adaptive_position( query:torch.Tensor, key:torch.Tensor,position_modified_ids=None)->torch.Tensor:\n",
    "    '''输入的维度应该是 \n",
    "    key: [batch, num_heads, seq_length, hidden_dim]\n",
    "    \n",
    "    in prefilling stage:\n",
    "    query: [batch, num_heads, seq_length, hidden_dim]\n",
    "    \n",
    "    in inference stage:\n",
    "    query: [batch, num_heads, 1, hidden_dim]'''\n",
    "    batch,num_heads = query.shape[0], query.shape[1]\n",
    "    if position_modified_ids == None:\n",
    "        #此时应该是预填充阶段\n",
    "        #注意要错位相乘, 因此query要去第一个, key要去最后一个\n",
    "        query = query[:,:,1:,:].unsqueeze(-2)\n",
    "        key = key[:,:,:-1,:].unsqueeze(-2)\n",
    "        distance = distance_fun(torch.matmul(query,key.transpose(-2,-1)).squeeze(-1)).transpose(-1,-2)\n",
    "        \n",
    "        #这个distance相比于真正的距离差着一个一号位, 我们都强制命令一号位的位置为0\n",
    "        distance_0 = torch.zeros((batch,num_heads,1,1),dtype=distance.dtype)\n",
    "        distance = torch.cat((distance_0,distance),dim=-1) #在一号位添加一个0\n",
    "        \n",
    "        position_modified_ids = distance.cumsum(dim=-1) #此时的输出维度是[batch,num_head, 1, seq_length]\n",
    "    \n",
    "    else:\n",
    "        #这个时候的输入一般是\"一个\"query, 我们的任务是计算新的query和倒数第二个key之间的距离.\n",
    "        \n",
    "        new_distance = distance_fun(torch.matmul(query, key[:,:,-2,:].unsqueeze(-2).transpose(-2,-1)))\n",
    "        position_modified_ids = new_distance + position_modified_ids[:,:,:,-1].unsqueeze(-2)\n",
    "    return position_modified_ids #返回的结果: 若是在pre-filling阶段, 则是[batch, num_head, 1, seq_length], 若是在推理阶段, 则是[batch, num_head,1,1]\n",
    "\n",
    "\n",
    "'''下面几个函数记得区分query_status和query_cache'''\n",
    "\n",
    "def query_select(query_status, block_ends, key_cache, block_lst:list):#从给定的blocks中挑选出来最有用的那个\n",
    "    #query: [1,hidden_dim]\n",
    "    #block_ends: list[int] \n",
    "    #key_cache : [cache_length,hidden_dim]\n",
    "    block_num = len(block_ends)\n",
    "    scores = []\n",
    "    for i in range(1,block_num):\n",
    "        start = block_ends[i-1]\n",
    "        end = block_ends[i]\n",
    "        key_status = key_cache[start:end,:]\n",
    "        score = torch.mean((query_status@key_status.T))\n",
    "        scores.append(score)\n",
    "    max_id = torch.argmax(torch.tensor(scores))+1\n",
    "    end = block_ends[max_id]\n",
    "    return block_lst.index(end)\n",
    "\n",
    "def block_trace(block_dependency,#这个block_dependecy是针对某个batch和head_idx的\n",
    "                select_block_id, \n",
    "                left_length,\n",
    "                block_lst,\n",
    "                position_method = 'origin',\n",
    "                block_size = 64): \n",
    "    #key_cache:[seq_length,hidden_dim]\n",
    "    #输入的left_length 是去除掉[skip_block]和[sink_block]以后的长度\n",
    "    select_keys_position = [[0,0]]\n",
    "\n",
    "    while block_dependency[select_block_id] != None and left_length>0: #此时说明select_block_id不是0\n",
    "        \n",
    "        end = block_lst[select_block_id]\n",
    "        start = block_lst[select_block_id-1]\n",
    "        select_keys_position = [[start,end]] + select_keys_position\n",
    "        if position_method == 'origin':\n",
    "            left_length -= (end-start)\n",
    "        elif position_method == 'modified':\n",
    "            left_length -= block_size\n",
    "        select_block_id = block_dependency[select_block_id]\n",
    "        #注意, 此函数只会追踪到倒数第二个block, 不会把第一个block的信息放到select_keys_position, 这个是给sink_block留下空间\n",
    "    return select_keys_position \n",
    "\n",
    "def query_aware(query_status:torch.Tensor, #[batch,num_heads, seq_length,hidden_dim]\n",
    "                key_cache, #[batch, num_heads,cache_length, hidden_dim]\n",
    "                value_cache,#[batch, num_heads,cache_length, hidden_dim]\n",
    "                position_ids, #这个很重要, 这个函数是对position_ids中的每个query计算其inference所用的keys #[1, seq_length]\n",
    "                #请注意: 这里的position_ids不是position_modified_ids, 这里的全部是整数, 和每个query一一对应\n",
    "                #并且它的长度是seq_length, 而不是cache_length\n",
    "                #layer_idx,\n",
    "                position_modified_ids, #[batch, num_heads, 1, cache_length]\n",
    "                block_status, \n",
    "                block_dependency, #block_dependency和block_status是不带layer_idx的, 因为block_cache.update的输出会有\n",
    "                max_length,\n",
    "                skip_num=5, #其实这个skip_block更应该叫做neighbor_block, 我懒得改了\n",
    "                find_num = 5,\n",
    "                position_method = 'origin',\n",
    "                block_size = 64):\n",
    "    #输入的query维度是[batch, num_head, seq_length, hidden_dim]\n",
    "    #输入的block是{batch1:{head1:[...],head2:[...],...},batch2:{head1:[...],head2:[...],...},...}\n",
    "    #输入的position_ids维度是[1,seq_length]\n",
    "    #输出是字典: {batch1:{head1:[[a1,a2,...],[b1,b2,...]]}}字典嵌套, 每个head的value是列表, 列表中每个元素是query挑选出来的token_ids, 列表的长度是seq_length\n",
    "    batch_size, head_num = query_status.shape[:2]\n",
    "    position_min = position_ids[0,0]\n",
    "    seq_length = position_ids.shape[-1]\n",
    "    keys_to_be_used = {}\n",
    "    values_to_be_used = {}\n",
    "    position_to_be_used = {}\n",
    "    for batch in range(batch_size):\n",
    "        keys_to_be_used[batch] = {} #理想状态的key_cache的组合应该是: [sink_block] + [select_block] + [skip_block]\n",
    "        values_to_be_used[batch] = {}\n",
    "        position_to_be_used[batch] = {}\n",
    "        for head_idx in range(head_num):\n",
    "            key_cache_to_be_used = key_cache[batch,head_idx,:,:]\n",
    "            values_cache_to_be_used = value_cache[batch,head_idx,:,:]\n",
    "            keys_to_be_used[batch][head_idx] = []\n",
    "            values_to_be_used[batch][head_idx] = []\n",
    "            position_to_be_used[batch][head_idx] = []\n",
    "\n",
    "            i = 0\n",
    "            #block_lst = block_status[layer_idx][batch][head_idx]\n",
    "            block_lst = block_status[batch][head_idx]\n",
    "            element_num = len(block_lst)\n",
    "            for delta in range(seq_length):\n",
    "                query_position = position_min+delta #query_position是query在seq 中的绝对位置, delta是在query_status中的绝对位置, 是在整个seq中的相对位置\n",
    "                while i < element_num and block_lst[i] < query_position: #lst中第i-1个元素就是我们要找的那个, 即共有0...i-1 共计i个元素在query前面\n",
    "                    i += 1\n",
    "                if i <= skip_num: #说明我这个query前面的所有key_cache都有用, 此时select_block, 所有的sink_block和skip_block, left_keys重合\n",
    "                    keys_to_be_used[batch][head_idx].append(key_cache_to_be_used[:query_position+1,:])\n",
    "                    values_to_be_used[batch][head_idx].append(values_cache_to_be_used[:query_position+1,:])\n",
    "                    if position_method == 'modified':\n",
    "                        position_to_be_used[batch][head_idx].append(position_modified_ids[batch,head_idx,0,:query_position+1].unsqueeze(0))\n",
    "                    else:\n",
    "                        position_to_be_used[batch][head_idx].append(torch.arange(query_position+1).long().unsqueeze(0))\n",
    "                else: #在这种状态下, key_cache的组合应该是: [sink_block] + [select_block] + [skip_block] + left_keys\n",
    "                    end = i-skip_num \n",
    "                    if end > find_num+1: \n",
    "                        start = end-find_num-1 #start >= 1\n",
    "                        #接下来的block_ends只是用来在其中根据query挑选一个最有用的出来, 使用函数query_select\n",
    "                        block_ends = block_lst[start:end] #注意, 此时len(block_ends) = end-start = find_num+1, 第一个元素是上个block的结尾\n",
    "                    else: #此时满足: 跳过了一些block, 然后剩下的block不够找出来所有的find_number了, select_block和sink_block有可能重合\n",
    "                        block_ends = [0] + block_lst[:end]\n",
    "                    selected_block_idx = query_select(\n",
    "                            query_status = query_status[batch,head_idx,delta,:],\n",
    "                            block_ends = block_ends, \n",
    "                            key_cache = key_cache[batch,head_idx,:,:],\n",
    "                            block_lst=block_lst) #注意: 返回的是block_lst中被选中的block的index, 若想知道真正的block的位置, 需要查询block_lst[idx]\n",
    "                    #selected_block_idx是query最关注的那个block的idx in block_lst\n",
    "                    if position_method == 'origin':\n",
    "                        skip_block_length = block_lst[i-1] - block_lst[end-1] \n",
    "                        sink_block_length = block_lst[0]\n",
    "                        left_keys_length = query_position-block_lst[i-1]\n",
    "                        left_length = max_length - (skip_block_length+sink_block_length+left_keys_length)\n",
    "                    elif position_method == 'modified':\n",
    "                        skip_block_length = block_size * skip_num\n",
    "                        sink_block_length = block_size\n",
    "                        \n",
    "                        query_modified_position = position_modified_ids[batch][head_idx][0][query_position]\n",
    "                        left_keys_length = query_modified_position-position_modified_ids[batch][head_idx][0][block_lst[i-1]]\n",
    "                        left_length = max_length - (skip_block_length+sink_block_length+left_keys_length)\n",
    "                \n",
    "                    '''\n",
    "                    left_length的计算可以修改, 比如使用position_modified_ids可以使推理时使用更多的tokens, 类似于插值的方法, 但是还需要进一步实验\n",
    "                    '''\n",
    "                    \n",
    "                    select_keys_position = block_trace(\n",
    "                        #block_dependency = block_dependency[layer_idx][batch][head_idx],\n",
    "                        block_dependency = block_dependency[batch][head_idx],\n",
    "                        select_block_id = selected_block_idx,\n",
    "                        left_length = left_length,\n",
    "                        block_lst= block_lst,\n",
    "                        position_method = position_method,\n",
    "                        block_size=block_size\n",
    "                    )#当selected_block_idx == 0时, 他的输出是[[0,0]], 若不是0, 则是类似于[[79,123],[261,337],...]\n",
    "                    \n",
    "\n",
    "                    skip_end = block_lst[i-1]\n",
    "                    skip_start = block_lst[i-1-skip_num]\n",
    "\n",
    "                    sink_block_key = key_cache_to_be_used[:block_lst[0],:] #这个东西永远是第一个block的信息\n",
    "                    sink_block_value = values_cache_to_be_used[:block_lst[0],:]\n",
    "                    select_blocks_key = torch.cat([key_cache_to_be_used[block[0]:block[1],:] for block in select_keys_position]\n",
    "                                                ,dim=-2)\n",
    "                    select_blocks_value = torch.cat([values_cache_to_be_used[block[0]:block[1],:] for block in select_keys_position]\n",
    "                                                ,dim=-2)\n",
    "                    skip_blocks_key = key_cache_to_be_used[skip_start:skip_end,:]\n",
    "                    skip_blocks_value = values_cache_to_be_used[skip_start:skip_end,:]\n",
    "                    left_keys = key_cache_to_be_used[block_lst[i-1]:query_position+1,:]#这是query前面, 但是却没有在任何一个block中的keys\n",
    "                    left_values = values_cache_to_be_used[block_lst[i-1]:query_position+1,:]\n",
    "                    keys_to_be_used[batch][head_idx].append(torch.cat([sink_block_key,select_blocks_key,skip_blocks_key,left_keys],dim=-2))\n",
    "                    v = torch.cat([sink_block_value,select_blocks_value,\n",
    "                                                                    skip_blocks_value,left_values],dim=-2)\n",
    "                    values_to_be_used[batch][head_idx].append(v)\n",
    "                    \n",
    "                    \n",
    "                    if position_method == 'modified':\n",
    "                        position_cache = position_modified_ids[batch,head_idx,0,:]\n",
    "                        sink_block_position = position_cache[:block_lst[0]]\n",
    "                        select_blocks_position = sink_block_position\n",
    "                        for block in select_keys_position:\n",
    "                            select = position_cache[block[0]:block[1]] - position_cache[block[0]]+select_blocks_position[-1]\n",
    "                            select_blocks_position = torch.cat([select_blocks_position,select], dim = 0)\n",
    "                        skip_blocks_position = position_cache[skip_start:skip_end] - position_cache[skip_start] + select_blocks_position[-1]\n",
    "                        left_postion = position_cache[block_lst[i-1]:query_position+1] - position_cache[block_lst[i-1]] + skip_blocks_position[-1]\n",
    "                        position_to_be_used[batch][head_idx].append(torch.cat([select_blocks_position,skip_blocks_position,left_postion],dim=0).unsqueeze(0))\n",
    "                        \n",
    "                    elif position_method == 'origin':\n",
    "                        position_to_be_used[batch][head_idx].append(\n",
    "                            torch.arange(len(v)).long().unsqueeze(0)\n",
    "                            )\n",
    "    return keys_to_be_used, values_to_be_used, position_to_be_used\n",
    "\n",
    "\n",
    "def get_key_value()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_block_score(query_cache,key_cache,obj_block, end_block,norm = 0): #把最后一个block当作end_block, 计算end_block和obj_block之间的分数\n",
    "    obj_key = key_cache[obj_block[0]:obj_block[1],:] #[obj_block_length, hidden_dim]\n",
    "    end_query = query_cache[end_block[0]-norm:end_block[1]-norm,:] #[end_block_length, hidden_dim]\n",
    "    score = torch.mean(end_query@obj_key.T)\n",
    "    return score\n",
    "\n",
    "\n",
    "def block_select(query_cache,key_cache,block_lst:List,neighbor_block_num,norm = 0):\n",
    "    #query_status:[seq_length, hidden_dim]\n",
    "    #key_cache : [cache_length, hidden_dim]\n",
    "    #block_lst : list[]\n",
    "    #输出为: block_list中最后一个block在neighbor_block中最关注的block的index\n",
    "    last_block_end = block_lst[-1]\n",
    "    last_block_start = block_lst[-2]\n",
    "    max_score = -1e10\n",
    "    \n",
    "    if len(block_lst)-1 <= neighbor_block_num: #说明前面的所有block都需要检查\n",
    "        block_lst = [0]+block_lst\n",
    "        for i in range(1,len(block_lst)-1):\n",
    "            obj_block = [block_lst[i-1],block_lst[i]]\n",
    "            score = get_block_score(query_cache, key_cache,obj_block,end_block=[last_block_start,last_block_end],norm = norm)\n",
    "            if score >= max_score:\n",
    "                max_score = score\n",
    "                max_id = i\n",
    "\n",
    "    elif len(block_lst)-1 > neighbor_block_num:\n",
    "        for i in range(-2, -neighbor_block_num-2,-1):\n",
    "            obj_block = [block_lst[i-1],block_lst[i]]\n",
    "            score = get_block_score(query_cache, key_cache,obj_block,[last_block_start,last_block_end], norm = norm)\n",
    "            if score >= max_score:\n",
    "                max_score = score\n",
    "                max_id = len(block_lst) + i\n",
    "    #len(socres) = neighbor_block_num\n",
    "    #max_id_reverse = int(torch.argmax(torch.tensor(scores)))-len(scores)\n",
    "    \n",
    "    return max_id\n",
    "\n",
    "\n",
    "\n",
    "def dependency_update(query_cache,key_cache,block_lst,block_dependency,neighbor_block_num,norm = 0):\n",
    "    if block_dependency == []:\n",
    "        block_dependency.append(None)\n",
    "        for i in range(1,len(block_lst)):\n",
    "            depend_idx = block_select(query_cache,key_cache,block_lst[:i+1],neighbor_block_num,norm = norm)\n",
    "            block_dependency.append(depend_idx)\n",
    "    else:\n",
    "        depend_idx = block_select(query_cache,key_cache,block_lst,neighbor_block_num,norm = norm)\n",
    "        block_dependency.append(depend_idx)\n",
    "    return block_dependency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block_Cache():\n",
    "    def __init__(self,block_size=64) -> None:\n",
    "        self.modified_position_cache:list[torch.Tensor] = []#列表中每个元素是三维的tensor[batch, num_heads, cache_length]\n",
    "        self.block_cache = [] #列表中每个元素是一个字典嵌套字典的结构{batch:{head_idx:[78,155,283,...]}}\n",
    "        self.block_size = block_size\n",
    "        self.query_cache = [] #{batch:{head_idx:[query_cache_length,hidden_dim]}}\n",
    "        self.dependency_cache = []#每一个元素都是一个dict{batch: {head_idx:[None, 78, 78,...]}} 其中列表的长度应该和block_cache中列表的长度相同\n",
    "\n",
    "\n",
    "    def update(self, \n",
    "               layer_idx: int,\n",
    "               query_status,#[batch, head_idx, seq_length,hidden_dim]\n",
    "               key_cache,#[batch, head_idx, cache_length,hidden_dim]\n",
    "               neighbor_block_num):\n",
    "        \n",
    "        if len(self.modified_position_cache) <= layer_idx:\n",
    "            position_modified_ids = adaptive_position(query_status,key_cache) #[batch, head_idx, seq_length,hidden_dim]\n",
    "            self.modified_position_cache.append(position_modified_ids)\n",
    "        else:\n",
    "            position_modified_ids = adaptive_position(query_status, key_cache, self.modified_position_cache[layer_idx])\n",
    "            self.modified_position_cache[layer_idx] = torch.cat([self.modified_position_cache[layer_idx], position_modified_ids], dim = -1)\n",
    "        \n",
    "        position_modified_ids = position_modified_ids % self.block_size\n",
    "        batch_size, num_heads = position_modified_ids.shape[0:2]\n",
    "        cache_length = self.modified_position_cache[layer_idx].shape[-1]\n",
    "\n",
    "        if len(self.block_cache) <= layer_idx:\n",
    "            block_layer = {}\n",
    "            dependency_layer = {}\n",
    "            query_cache_layer = {}\n",
    "            for batch in range(batch_size):\n",
    "                block_layer[batch] = {}\n",
    "                dependency_layer[batch] = {}\n",
    "                query_cache_layer[batch] = {}\n",
    "                for head_idx in range(num_heads):\n",
    "                    block_layer[batch][head_idx] = [] #这个是block_lst\n",
    "                    dependency_layer[batch][head_idx] = [] #这个是block_dependency, 他的长度和block_lst相同\n",
    "                    # query_cache_layer[batch][head_idx]这个的长度是动态的\n",
    "                    for i in range(1,cache_length):\n",
    "                        if position_modified_ids[batch,head_idx,0,i] < position_modified_ids[batch,head_idx,0,i-1]: #记录每个block的最后一个token后一个的位置, 这是为了在之后切片的时候统一计算\n",
    "                            block_layer[batch][head_idx].append(i)\n",
    "                    block_lst = block_layer[batch][head_idx]\n",
    "                    block_dependency = dependency_layer[batch][head_idx]\n",
    "                    block_dependency = dependency_update(query_status[batch,head_idx,:,:],\n",
    "                                                         key_cache[batch,head_idx,:,:],\n",
    "                                                         block_lst,block_dependency,neighbor_block_num)\n",
    "                    if block_lst == []:\n",
    "                        query_cache_layer[batch][head_idx] = query_status[batch,head_idx,:,:]\n",
    "                    else:\n",
    "                        query_cache_layer[batch][head_idx] = query_status[batch,head_idx,block_lst[-1]:,:]\n",
    "\n",
    "            self.block_cache.append(block_layer)\n",
    "            self.dependency_cache.append(dependency_layer)\n",
    "            self.query_cache.append(query_cache_layer)\n",
    "\n",
    "        else:\n",
    "            block_layer = self.block_cache[layer_idx]\n",
    "            dependency_layer = self.dependency_cache[layer_idx]\n",
    "            query_cache_layer = self.query_cache[layer_idx]\n",
    "            assert position_modified_ids.shape[2] == 1 , f'在推理阶段假设一次只新增一个token, 而现在新增了{position_modified_ids.shape[2]}个'\n",
    "            \n",
    "            for batch in range(batch_size):\n",
    "                for head_idx in range(num_heads):\n",
    "                    position_ids = self.modified_position_cache[layer_idx] #在这一步的时候, self.modified_position_cache已经更新过了\n",
    "                    self.query_cache[layer_idx][batch][head_idx] = torch.cat([self.query_cache[layer_idx][batch][head_idx],query_status[batch,layer_idx,:,:]],dim=0)\n",
    "                    if position_ids[batch,head_idx,0,-1] <  position_ids[batch,head_idx,0,-2]:\n",
    "                        block_layer[batch][head_idx].append(cache_length)\n",
    "                        dependency_layer[batch][head_idx] = dependency_update(query_cache = self.query_cache[layer_idx][batch][head_idx],\n",
    "                                                                              key_cache = key_cache[batch,head_idx,:,:],\n",
    "                                                                              block_lst=block_layer[batch][head_idx],\n",
    "                                                                              block_dependency=dependency_layer[batch][head_idx],\n",
    "                                                                              neighbor_block_num=neighbor_block_num,\n",
    "                                                                              norm = block_layer[batch][head_idx][-2])\n",
    "        return self.modified_position_cache[layer_idx], self.block_cache[layer_idx], self.dependency_cache[layer_idx]\n",
    "    \n",
    "\n",
    "    def get_status(self,layer_idx):\n",
    "        if len(self.block_cache) <= layer_idx:\n",
    "            return None\n",
    "        else: \n",
    "            return self.modified_position_cache[layer_idx], self.block_cache[layer_idx]\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 0.0759,  0.1761, -0.5493]]),\n",
       " tensor([[ 0.0759,  0.1761, -0.5493],\n",
       "         [-0.6124,  0.5323, -1.2284]]),\n",
       " tensor([[ 0.0759,  0.1761, -0.5493],\n",
       "         [-0.6124,  0.5323, -1.2284],\n",
       "         [ 0.0125,  0.4428, -0.8751]]),\n",
       " tensor([[ 0.0759,  0.1761, -0.5493],\n",
       "         [-0.6124,  0.5323, -1.2284],\n",
       "         [ 0.0125,  0.4428, -0.8751],\n",
       "         [-0.5447,  0.2373,  1.7358]]),\n",
       " tensor([[ 0.0759,  0.1761, -0.5493],\n",
       "         [-0.6124,  0.5323, -1.2284],\n",
       "         [ 0.0125,  0.4428, -0.8751],\n",
       "         [-0.5447,  0.2373,  1.7358],\n",
       "         [-1.4266,  0.4551, -0.0601]]),\n",
       " tensor([[ 0.0759,  0.1761, -0.5493],\n",
       "         [-0.6124,  0.5323, -1.2284],\n",
       "         [ 0.0125,  0.4428, -0.8751],\n",
       "         [-0.5447,  0.2373,  1.7358],\n",
       "         [-1.4266,  0.4551, -0.0601],\n",
       "         [-0.0516, -0.3702, -0.5804]]),\n",
       " tensor([[ 0.0759,  0.1761, -0.5493],\n",
       "         [-0.6124,  0.5323, -1.2284],\n",
       "         [ 0.0125,  0.4428, -0.8751],\n",
       "         [-0.5447,  0.2373,  1.7358],\n",
       "         [-1.4266,  0.4551, -0.0601],\n",
       "         [-0.0516, -0.3702, -0.5804],\n",
       "         [-0.5378,  0.7622, -1.2412]]),\n",
       " tensor([[ 0.0759,  0.1761, -0.5493],\n",
       "         [-0.6124,  0.5323, -1.2284],\n",
       "         [ 0.0125,  0.4428, -0.8751],\n",
       "         [-0.5447,  0.2373,  1.7358],\n",
       "         [-1.4266,  0.4551, -0.0601],\n",
       "         [-0.0516, -0.3702, -0.5804],\n",
       "         [-0.5378,  0.7622, -1.2412],\n",
       "         [ 0.2852,  1.3993,  0.7797]]),\n",
       " tensor([[ 0.0759,  0.1761, -0.5493],\n",
       "         [-0.6124,  0.5323, -1.2284],\n",
       "         [ 0.0125,  0.4428, -0.8751],\n",
       "         [-0.5447,  0.2373,  1.7358],\n",
       "         [-1.4266,  0.4551, -0.0601],\n",
       "         [-0.0516, -0.3702, -0.5804],\n",
       "         [-0.5378,  0.7622, -1.2412],\n",
       "         [ 0.2852,  1.3993,  0.7797],\n",
       "         [ 1.6258,  0.4506, -0.6614]]),\n",
       " tensor([[ 0.0759,  0.1761, -0.5493],\n",
       "         [-0.6124,  0.5323, -1.2284],\n",
       "         [ 0.0125,  0.4428, -0.8751],\n",
       "         [-0.5447,  0.2373,  1.7358],\n",
       "         [-1.4266,  0.4551, -0.0601],\n",
       "         [-0.0516, -0.3702, -0.5804],\n",
       "         [-0.5378,  0.7622, -1.2412],\n",
       "         [ 0.2852,  1.3993,  0.7797],\n",
       "         [ 1.6258,  0.4506, -0.6614],\n",
       "         [-0.4807,  1.0644, -0.6048]]),\n",
       " tensor([[ 0.0759,  0.1761, -0.5493],\n",
       "         [-0.6124,  0.5323, -1.2284],\n",
       "         [ 0.0125,  0.4428, -0.8751],\n",
       "         [-0.5447,  0.2373,  1.7358],\n",
       "         [-1.4266,  0.4551, -0.0601],\n",
       "         [-0.0516, -0.3702, -0.5804],\n",
       "         [-0.5378,  0.7622, -1.2412],\n",
       "         [ 0.2852,  1.3993,  0.7797],\n",
       "         [ 1.6258,  0.4506, -0.6614],\n",
       "         [-0.4807,  1.0644, -0.6048],\n",
       "         [ 1.6903, -0.8785, -2.3347]]),\n",
       " tensor([[ 0.0759,  0.1761, -0.5493],\n",
       "         [-0.6124,  0.5323, -1.2284],\n",
       "         [ 0.0125,  0.4428, -0.8751],\n",
       "         [-0.5447,  0.2373,  1.7358],\n",
       "         [-1.4266,  0.4551, -0.0601],\n",
       "         [-0.0516, -0.3702, -0.5804],\n",
       "         [-0.5378,  0.7622, -1.2412],\n",
       "         [ 0.2852,  1.3993,  0.7797],\n",
       "         [ 1.6258,  0.4506, -0.6614],\n",
       "         [-0.4807,  1.0644, -0.6048],\n",
       "         [ 1.6903, -0.8785, -2.3347],\n",
       "         [-0.9651, -1.5319,  0.8214]]),\n",
       " tensor([[ 0.0759,  0.1761, -0.5493],\n",
       "         [-0.6124,  0.5323, -1.2284],\n",
       "         [ 0.0125,  0.4428, -0.8751],\n",
       "         [-0.5447,  0.2373,  1.7358],\n",
       "         [-1.4266,  0.4551, -0.0601],\n",
       "         [-0.0516, -0.3702, -0.5804],\n",
       "         [-0.5378,  0.7622, -1.2412],\n",
       "         [ 0.2852,  1.3993,  0.7797],\n",
       "         [ 1.6258,  0.4506, -0.6614],\n",
       "         [-0.4807,  1.0644, -0.6048],\n",
       "         [ 1.6903, -0.8785, -2.3347],\n",
       "         [-0.9651, -1.5319,  0.8214],\n",
       "         [-0.0761,  0.3362,  1.4899]]),\n",
       " tensor([[ 0.0759,  0.1761, -0.5493],\n",
       "         [-0.6124,  0.5323, -1.2284],\n",
       "         [ 0.0125,  0.4428, -0.8751],\n",
       "         [-0.5447,  0.2373,  1.7358],\n",
       "         [-1.4266,  0.4551, -0.0601],\n",
       "         [-0.0516, -0.3702, -0.5804],\n",
       "         [-0.5378,  0.7622, -1.2412],\n",
       "         [ 0.2852,  1.3993,  0.7797],\n",
       "         [ 1.6258,  0.4506, -0.6614],\n",
       "         [-0.4807,  1.0644, -0.6048],\n",
       "         [ 1.6903, -0.8785, -2.3347],\n",
       "         [-0.9651, -1.5319,  0.8214],\n",
       "         [-0.0761,  0.3362,  1.4899],\n",
       "         [ 1.6011,  0.2875,  0.1907]]),\n",
       " tensor([[ 0.0759,  0.1761, -0.5493],\n",
       "         [-0.6124,  0.5323, -1.2284],\n",
       "         [ 0.0125,  0.4428, -0.8751],\n",
       "         [-0.5447,  0.2373,  1.7358],\n",
       "         [-1.4266,  0.4551, -0.0601],\n",
       "         [-0.0516, -0.3702, -0.5804],\n",
       "         [-0.5378,  0.7622, -1.2412],\n",
       "         [ 0.2852,  1.3993,  0.7797],\n",
       "         [ 1.6258,  0.4506, -0.6614],\n",
       "         [-0.4807,  1.0644, -0.6048],\n",
       "         [ 1.6903, -0.8785, -2.3347],\n",
       "         [-0.9651, -1.5319,  0.8214],\n",
       "         [-0.0761,  0.3362,  1.4899],\n",
       "         [ 1.6011,  0.2875,  0.1907],\n",
       "         [-0.8210,  1.0341,  2.3723]]),\n",
       " tensor([[ 0.0759,  0.1761, -0.5493],\n",
       "         [-0.6124,  0.5323, -1.2284],\n",
       "         [ 0.0125,  0.4428, -0.8751],\n",
       "         [-0.5447,  0.2373,  1.7358],\n",
       "         [-1.4266,  0.4551, -0.0601],\n",
       "         [-0.0516, -0.3702, -0.5804],\n",
       "         [-0.5378,  0.7622, -1.2412],\n",
       "         [ 0.2852,  1.3993,  0.7797],\n",
       "         [ 1.6258,  0.4506, -0.6614],\n",
       "         [-0.4807,  1.0644, -0.6048],\n",
       "         [ 1.6903, -0.8785, -2.3347],\n",
       "         [-0.9651, -1.5319,  0.8214],\n",
       "         [-0.0761,  0.3362,  1.4899],\n",
       "         [ 1.6011,  0.2875,  0.1907],\n",
       "         [-0.8210,  1.0341,  2.3723],\n",
       "         [ 1.2841,  0.8247, -0.5056]]),\n",
       " tensor([[ 0.0759,  0.1761, -0.5493],\n",
       "         [-0.6124,  0.5323, -1.2284],\n",
       "         [ 0.0125,  0.4428, -0.8751],\n",
       "         [-0.5447,  0.2373,  1.7358],\n",
       "         [-1.4266,  0.4551, -0.0601],\n",
       "         [-0.0516, -0.3702, -0.5804],\n",
       "         [-0.5378,  0.7622, -1.2412],\n",
       "         [ 0.2852,  1.3993,  0.7797],\n",
       "         [ 1.6258,  0.4506, -0.6614],\n",
       "         [-0.4807,  1.0644, -0.6048],\n",
       "         [ 1.6903, -0.8785, -2.3347],\n",
       "         [-0.9651, -1.5319,  0.8214],\n",
       "         [-0.0761,  0.3362,  1.4899],\n",
       "         [ 1.6011,  0.2875,  0.1907],\n",
       "         [-0.8210,  1.0341,  2.3723],\n",
       "         [ 1.2841,  0.8247, -0.5056],\n",
       "         [ 0.2292,  1.5156, -0.1988]]),\n",
       " tensor([[ 0.0759,  0.1761, -0.5493],\n",
       "         [-0.6124,  0.5323, -1.2284],\n",
       "         [ 0.0125,  0.4428, -0.8751],\n",
       "         [-0.5447,  0.2373,  1.7358],\n",
       "         [-1.4266,  0.4551, -0.0601],\n",
       "         [-0.0516, -0.3702, -0.5804],\n",
       "         [-0.5378,  0.7622, -1.2412],\n",
       "         [ 0.2852,  1.3993,  0.7797],\n",
       "         [ 1.6258,  0.4506, -0.6614],\n",
       "         [-0.4807,  1.0644, -0.6048],\n",
       "         [ 1.6903, -0.8785, -2.3347],\n",
       "         [-0.9651, -1.5319,  0.8214],\n",
       "         [-0.0761,  0.3362,  1.4899],\n",
       "         [ 1.6011,  0.2875,  0.1907],\n",
       "         [-0.8210,  1.0341,  2.3723],\n",
       "         [ 1.2841,  0.8247, -0.5056],\n",
       "         [ 0.2292,  1.5156, -0.1988],\n",
       "         [-0.2456, -0.6490,  1.1071]]),\n",
       " tensor([[ 0.0759,  0.1761, -0.5493],\n",
       "         [-0.6124,  0.5323, -1.2284],\n",
       "         [ 0.0125,  0.4428, -0.8751],\n",
       "         [-0.5447,  0.2373,  1.7358],\n",
       "         [-1.4266,  0.4551, -0.0601],\n",
       "         [-0.0516, -0.3702, -0.5804],\n",
       "         [-0.5378,  0.7622, -1.2412],\n",
       "         [ 0.2852,  1.3993,  0.7797],\n",
       "         [ 1.6258,  0.4506, -0.6614],\n",
       "         [-0.4807,  1.0644, -0.6048],\n",
       "         [ 1.6903, -0.8785, -2.3347],\n",
       "         [-0.9651, -1.5319,  0.8214],\n",
       "         [-0.0761,  0.3362,  1.4899],\n",
       "         [ 1.6011,  0.2875,  0.1907],\n",
       "         [-0.8210,  1.0341,  2.3723],\n",
       "         [ 1.2841,  0.8247, -0.5056],\n",
       "         [ 0.2292,  1.5156, -0.1988],\n",
       "         [-0.2456, -0.6490,  1.1071],\n",
       "         [ 0.0639, -0.2898, -0.1037]]),\n",
       " tensor([[ 0.0759,  0.1761, -0.5493],\n",
       "         [-0.6124,  0.5323, -1.2284],\n",
       "         [ 0.0125,  0.4428, -0.8751],\n",
       "         [-0.5447,  0.2373,  1.7358],\n",
       "         [-1.4266,  0.4551, -0.0601],\n",
       "         [-0.0516, -0.3702, -0.5804],\n",
       "         [-0.5378,  0.7622, -1.2412],\n",
       "         [ 0.2852,  1.3993,  0.7797],\n",
       "         [ 1.6258,  0.4506, -0.6614],\n",
       "         [-0.4807,  1.0644, -0.6048],\n",
       "         [ 1.6903, -0.8785, -2.3347],\n",
       "         [-0.9651, -1.5319,  0.8214],\n",
       "         [-0.0761,  0.3362,  1.4899],\n",
       "         [ 1.6011,  0.2875,  0.1907],\n",
       "         [-0.8210,  1.0341,  2.3723],\n",
       "         [ 1.2841,  0.8247, -0.5056],\n",
       "         [ 0.2292,  1.5156, -0.1988],\n",
       "         [-0.2456, -0.6490,  1.1071],\n",
       "         [ 0.0639, -0.2898, -0.1037],\n",
       "         [ 0.2321,  2.0379,  1.3737]]),\n",
       " tensor([[ 0.0759,  0.1761, -0.5493],\n",
       "         [-0.6124,  0.5323, -1.2284],\n",
       "         [ 0.0125,  0.4428, -0.8751],\n",
       "         [-0.5447,  0.2373,  1.7358],\n",
       "         [-1.4266,  0.4551, -0.0601],\n",
       "         [-0.0516, -0.3702, -0.5804],\n",
       "         [-0.5378,  0.7622, -1.2412],\n",
       "         [ 0.2852,  1.3993,  0.7797],\n",
       "         [ 1.6258,  0.4506, -0.6614],\n",
       "         [-0.4807,  1.0644, -0.6048],\n",
       "         [ 1.6903, -0.8785, -2.3347],\n",
       "         [-0.9651, -1.5319,  0.8214],\n",
       "         [-0.0761,  0.3362,  1.4899],\n",
       "         [ 1.6011,  0.2875,  0.1907],\n",
       "         [-0.8210,  1.0341,  2.3723],\n",
       "         [ 1.2841,  0.8247, -0.5056],\n",
       "         [ 0.2292,  1.5156, -0.1988],\n",
       "         [-0.2456, -0.6490,  1.1071],\n",
       "         [ 0.0639, -0.2898, -0.1037],\n",
       "         [ 0.2321,  2.0379,  1.3737]]),\n",
       " tensor([[ 0.0759,  0.1761, -0.5493],\n",
       "         [-0.6124,  0.5323, -1.2284],\n",
       "         [ 0.0125,  0.4428, -0.8751],\n",
       "         [-0.5447,  0.2373,  1.7358],\n",
       "         [-1.4266,  0.4551, -0.0601],\n",
       "         [-0.0516, -0.3702, -0.5804],\n",
       "         [-0.5378,  0.7622, -1.2412],\n",
       "         [ 0.2852,  1.3993,  0.7797],\n",
       "         [ 1.6258,  0.4506, -0.6614],\n",
       "         [-0.4807,  1.0644, -0.6048],\n",
       "         [ 1.6903, -0.8785, -2.3347],\n",
       "         [-0.9651, -1.5319,  0.8214],\n",
       "         [-0.0761,  0.3362,  1.4899],\n",
       "         [ 1.6011,  0.2875,  0.1907],\n",
       "         [-0.8210,  1.0341,  2.3723],\n",
       "         [ 1.2841,  0.8247, -0.5056],\n",
       "         [ 0.2292,  1.5156, -0.1988],\n",
       "         [-0.2456, -0.6490,  1.1071],\n",
       "         [ 0.0639, -0.2898, -0.1037],\n",
       "         [ 0.2321,  2.0379,  1.3737]]),\n",
       " tensor([[ 0.0759,  0.1761, -0.5493],\n",
       "         [-0.6124,  0.5323, -1.2284],\n",
       "         [ 0.0125,  0.4428, -0.8751],\n",
       "         [-0.5447,  0.2373,  1.7358],\n",
       "         [-1.4266,  0.4551, -0.0601],\n",
       "         [-0.0516, -0.3702, -0.5804],\n",
       "         [-0.5378,  0.7622, -1.2412],\n",
       "         [ 0.2852,  1.3993,  0.7797],\n",
       "         [ 1.6258,  0.4506, -0.6614],\n",
       "         [-0.4807,  1.0644, -0.6048],\n",
       "         [ 1.6903, -0.8785, -2.3347],\n",
       "         [-0.9651, -1.5319,  0.8214],\n",
       "         [-0.0761,  0.3362,  1.4899],\n",
       "         [ 1.6011,  0.2875,  0.1907],\n",
       "         [-0.8210,  1.0341,  2.3723],\n",
       "         [ 1.2841,  0.8247, -0.5056],\n",
       "         [ 0.2292,  1.5156, -0.1988],\n",
       "         [-0.2456, -0.6490,  1.1071],\n",
       "         [ 0.0639, -0.2898, -0.1037],\n",
       "         [ 0.2321,  2.0379,  1.3737]]),\n",
       " tensor([[ 0.0759,  0.1761, -0.5493],\n",
       "         [-0.6124,  0.5323, -1.2284],\n",
       "         [ 0.0125,  0.4428, -0.8751],\n",
       "         [-0.5447,  0.2373,  1.7358],\n",
       "         [-1.4266,  0.4551, -0.0601],\n",
       "         [-0.0516, -0.3702, -0.5804],\n",
       "         [-0.5378,  0.7622, -1.2412],\n",
       "         [ 0.2852,  1.3993,  0.7797],\n",
       "         [ 1.6258,  0.4506, -0.6614],\n",
       "         [-0.4807,  1.0644, -0.6048],\n",
       "         [ 1.6903, -0.8785, -2.3347],\n",
       "         [-0.9651, -1.5319,  0.8214],\n",
       "         [-0.0761,  0.3362,  1.4899],\n",
       "         [ 1.6011,  0.2875,  0.1907],\n",
       "         [-0.8210,  1.0341,  2.3723],\n",
       "         [ 1.2841,  0.8247, -0.5056],\n",
       "         [ 0.2292,  1.5156, -0.1988],\n",
       "         [-0.2456, -0.6490,  1.1071],\n",
       "         [ 0.0639, -0.2898, -0.1037],\n",
       "         [ 0.2321,  2.0379,  1.3737]]),\n",
       " tensor([[ 0.0759,  0.1761, -0.5493],\n",
       "         [-0.6124,  0.5323, -1.2284],\n",
       "         [ 0.0125,  0.4428, -0.8751],\n",
       "         [-0.5447,  0.2373,  1.7358],\n",
       "         [-1.4266,  0.4551, -0.0601],\n",
       "         [-0.0516, -0.3702, -0.5804],\n",
       "         [-0.5378,  0.7622, -1.2412],\n",
       "         [ 0.2852,  1.3993,  0.7797],\n",
       "         [ 1.6258,  0.4506, -0.6614],\n",
       "         [-0.4807,  1.0644, -0.6048],\n",
       "         [ 1.6903, -0.8785, -2.3347],\n",
       "         [-0.5378,  0.7622, -1.2412],\n",
       "         [ 0.2852,  1.3993,  0.7797],\n",
       "         [ 1.6258,  0.4506, -0.6614],\n",
       "         [-0.4807,  1.0644, -0.6048],\n",
       "         [ 1.6903, -0.8785, -2.3347],\n",
       "         [-0.5378,  0.7622, -1.2412],\n",
       "         [ 0.2852,  1.3993,  0.7797],\n",
       "         [ 1.6258,  0.4506, -0.6614],\n",
       "         [-0.4807,  1.0644, -0.6048],\n",
       "         [ 1.6903, -0.8785, -2.3347],\n",
       "         [-0.5378,  0.7622, -1.2412],\n",
       "         [ 0.2852,  1.3993,  0.7797],\n",
       "         [ 1.6258,  0.4506, -0.6614],\n",
       "         [-0.4807,  1.0644, -0.6048],\n",
       "         [ 1.6903, -0.8785, -2.3347],\n",
       "         [-0.5378,  0.7622, -1.2412],\n",
       "         [ 0.2852,  1.3993,  0.7797],\n",
       "         [ 1.6258,  0.4506, -0.6614],\n",
       "         [-0.4807,  1.0644, -0.6048],\n",
       "         [ 1.6903, -0.8785, -2.3347],\n",
       "         [-0.5378,  0.7622, -1.2412],\n",
       "         [ 0.2852,  1.3993,  0.7797],\n",
       "         [ 1.6258,  0.4506, -0.6614],\n",
       "         [-0.4807,  1.0644, -0.6048],\n",
       "         [ 1.6903, -0.8785, -2.3347],\n",
       "         [-0.5378,  0.7622, -1.2412],\n",
       "         [ 0.2852,  1.3993,  0.7797],\n",
       "         [ 1.6258,  0.4506, -0.6614],\n",
       "         [-0.4807,  1.0644, -0.6048],\n",
       "         [ 1.6903, -0.8785, -2.3347],\n",
       "         [-0.5378,  0.7622, -1.2412],\n",
       "         [ 0.2852,  1.3993,  0.7797],\n",
       "         [ 1.6258,  0.4506, -0.6614],\n",
       "         [-0.4807,  1.0644, -0.6048],\n",
       "         [ 1.6903, -0.8785, -2.3347],\n",
       "         [-0.5378,  0.7622, -1.2412],\n",
       "         [ 0.2852,  1.3993,  0.7797],\n",
       "         [ 1.6258,  0.4506, -0.6614],\n",
       "         [-0.4807,  1.0644, -0.6048],\n",
       "         [ 1.6903, -0.8785, -2.3347],\n",
       "         [-0.5378,  0.7622, -1.2412],\n",
       "         [ 0.2852,  1.3993,  0.7797],\n",
       "         [ 1.6258,  0.4506, -0.6614],\n",
       "         [-0.4807,  1.0644, -0.6048],\n",
       "         [ 1.6903, -0.8785, -2.3347],\n",
       "         [-0.5378,  0.7622, -1.2412],\n",
       "         [ 0.2852,  1.3993,  0.7797],\n",
       "         [ 1.6258,  0.4506, -0.6614],\n",
       "         [-0.4807,  1.0644, -0.6048],\n",
       "         [ 1.6903, -0.8785, -2.3347],\n",
       "         [-0.5378,  0.7622, -1.2412],\n",
       "         [ 0.2852,  1.3993,  0.7797],\n",
       "         [ 1.6258,  0.4506, -0.6614],\n",
       "         [-0.4807,  1.0644, -0.6048],\n",
       "         [ 1.6903, -0.8785, -2.3347],\n",
       "         [-0.5378,  0.7622, -1.2412],\n",
       "         [ 0.2852,  1.3993,  0.7797],\n",
       "         [ 1.6258,  0.4506, -0.6614],\n",
       "         [-0.4807,  1.0644, -0.6048],\n",
       "         [ 1.6903, -0.8785, -2.3347],\n",
       "         [-0.5378,  0.7622, -1.2412],\n",
       "         [ 0.2852,  1.3993,  0.7797],\n",
       "         [ 1.6258,  0.4506, -0.6614],\n",
       "         [-0.4807,  1.0644, -0.6048],\n",
       "         [ 1.6903, -0.8785, -2.3347],\n",
       "         [-0.5378,  0.7622, -1.2412],\n",
       "         [ 0.2852,  1.3993,  0.7797],\n",
       "         [ 1.6258,  0.4506, -0.6614],\n",
       "         [-0.4807,  1.0644, -0.6048],\n",
       "         [ 1.6903, -0.8785, -2.3347],\n",
       "         [-0.5378,  0.7622, -1.2412],\n",
       "         [ 0.2852,  1.3993,  0.7797],\n",
       "         [ 1.6258,  0.4506, -0.6614],\n",
       "         [-0.4807,  1.0644, -0.6048],\n",
       "         [ 1.6903, -0.8785, -2.3347],\n",
       "         [-0.5378,  0.7622, -1.2412],\n",
       "         [ 0.2852,  1.3993,  0.7797],\n",
       "         [ 1.6258,  0.4506, -0.6614],\n",
       "         [-0.4807,  1.0644, -0.6048],\n",
       "         [ 1.6903, -0.8785, -2.3347],\n",
       "         [-0.9651, -1.5319,  0.8214],\n",
       "         [-0.0761,  0.3362,  1.4899],\n",
       "         [ 1.6011,  0.2875,  0.1907],\n",
       "         [-0.8210,  1.0341,  2.3723],\n",
       "         [ 1.2841,  0.8247, -0.5056],\n",
       "         [ 0.2292,  1.5156, -0.1988],\n",
       "         [-0.2456, -0.6490,  1.1071],\n",
       "         [ 0.0639, -0.2898, -0.1037],\n",
       "         [ 0.2321,  2.0379,  1.3737]]),\n",
       " tensor([[ 0.0759,  0.1761, -0.5493],\n",
       "         [-0.6124,  0.5323, -1.2284],\n",
       "         [ 0.0125,  0.4428, -0.8751],\n",
       "         [-0.5447,  0.2373,  1.7358],\n",
       "         [-1.4266,  0.4551, -0.0601],\n",
       "         [-0.0516, -0.3702, -0.5804],\n",
       "         [-0.9651, -1.5319,  0.8214],\n",
       "         [-0.0761,  0.3362,  1.4899],\n",
       "         [ 1.6011,  0.2875,  0.1907],\n",
       "         [-0.8210,  1.0341,  2.3723],\n",
       "         [ 1.2841,  0.8247, -0.5056],\n",
       "         [ 0.2292,  1.5156, -0.1988],\n",
       "         [-0.2456, -0.6490,  1.1071],\n",
       "         [ 0.0639, -0.2898, -0.1037],\n",
       "         [ 0.2321,  2.0379,  1.3737]]),\n",
       " tensor([[ 0.0759,  0.1761, -0.5493],\n",
       "         [-0.6124,  0.5323, -1.2284],\n",
       "         [ 0.0125,  0.4428, -0.8751],\n",
       "         [-0.5447,  0.2373,  1.7358],\n",
       "         [-1.4266,  0.4551, -0.0601],\n",
       "         [-0.0516, -0.3702, -0.5804],\n",
       "         [-0.5378,  0.7622, -1.2412],\n",
       "         [ 0.2852,  1.3993,  0.7797],\n",
       "         [ 1.6258,  0.4506, -0.6614],\n",
       "         [-0.4807,  1.0644, -0.6048],\n",
       "         [ 1.6903, -0.8785, -2.3347],\n",
       "         [-0.5378,  0.7622, -1.2412],\n",
       "         [ 0.2852,  1.3993,  0.7797],\n",
       "         [ 1.6258,  0.4506, -0.6614],\n",
       "         [-0.4807,  1.0644, -0.6048],\n",
       "         [ 1.6903, -0.8785, -2.3347],\n",
       "         [-0.5378,  0.7622, -1.2412],\n",
       "         [ 0.2852,  1.3993,  0.7797],\n",
       "         [ 1.6258,  0.4506, -0.6614],\n",
       "         [-0.4807,  1.0644, -0.6048],\n",
       "         [ 1.6903, -0.8785, -2.3347],\n",
       "         [-0.5378,  0.7622, -1.2412],\n",
       "         [ 0.2852,  1.3993,  0.7797],\n",
       "         [ 1.6258,  0.4506, -0.6614],\n",
       "         [-0.4807,  1.0644, -0.6048],\n",
       "         [ 1.6903, -0.8785, -2.3347],\n",
       "         [-0.5378,  0.7622, -1.2412],\n",
       "         [ 0.2852,  1.3993,  0.7797],\n",
       "         [ 1.6258,  0.4506, -0.6614],\n",
       "         [-0.4807,  1.0644, -0.6048],\n",
       "         [ 1.6903, -0.8785, -2.3347],\n",
       "         [-0.5378,  0.7622, -1.2412],\n",
       "         [ 0.2852,  1.3993,  0.7797],\n",
       "         [ 1.6258,  0.4506, -0.6614],\n",
       "         [-0.4807,  1.0644, -0.6048],\n",
       "         [ 1.6903, -0.8785, -2.3347],\n",
       "         [-0.5378,  0.7622, -1.2412],\n",
       "         [ 0.2852,  1.3993,  0.7797],\n",
       "         [ 1.6258,  0.4506, -0.6614],\n",
       "         [-0.4807,  1.0644, -0.6048],\n",
       "         [ 1.6903, -0.8785, -2.3347],\n",
       "         [-0.5378,  0.7622, -1.2412],\n",
       "         [ 0.2852,  1.3993,  0.7797],\n",
       "         [ 1.6258,  0.4506, -0.6614],\n",
       "         [-0.4807,  1.0644, -0.6048],\n",
       "         [ 1.6903, -0.8785, -2.3347],\n",
       "         [-0.5378,  0.7622, -1.2412],\n",
       "         [ 0.2852,  1.3993,  0.7797],\n",
       "         [ 1.6258,  0.4506, -0.6614],\n",
       "         [-0.4807,  1.0644, -0.6048],\n",
       "         [ 1.6903, -0.8785, -2.3347],\n",
       "         [-0.5378,  0.7622, -1.2412],\n",
       "         [ 0.2852,  1.3993,  0.7797],\n",
       "         [ 1.6258,  0.4506, -0.6614],\n",
       "         [-0.4807,  1.0644, -0.6048],\n",
       "         [ 1.6903, -0.8785, -2.3347],\n",
       "         [-0.5378,  0.7622, -1.2412],\n",
       "         [ 0.2852,  1.3993,  0.7797],\n",
       "         [ 1.6258,  0.4506, -0.6614],\n",
       "         [-0.4807,  1.0644, -0.6048],\n",
       "         [ 1.6903, -0.8785, -2.3347],\n",
       "         [-0.5378,  0.7622, -1.2412],\n",
       "         [ 0.2852,  1.3993,  0.7797],\n",
       "         [ 1.6258,  0.4506, -0.6614],\n",
       "         [-0.4807,  1.0644, -0.6048],\n",
       "         [ 1.6903, -0.8785, -2.3347],\n",
       "         [-0.5378,  0.7622, -1.2412],\n",
       "         [ 0.2852,  1.3993,  0.7797],\n",
       "         [ 1.6258,  0.4506, -0.6614],\n",
       "         [-0.4807,  1.0644, -0.6048],\n",
       "         [ 1.6903, -0.8785, -2.3347],\n",
       "         [-0.5378,  0.7622, -1.2412],\n",
       "         [ 0.2852,  1.3993,  0.7797],\n",
       "         [ 1.6258,  0.4506, -0.6614],\n",
       "         [-0.4807,  1.0644, -0.6048],\n",
       "         [ 1.6903, -0.8785, -2.3347],\n",
       "         [-0.5378,  0.7622, -1.2412],\n",
       "         [ 0.2852,  1.3993,  0.7797],\n",
       "         [ 1.6258,  0.4506, -0.6614],\n",
       "         [-0.4807,  1.0644, -0.6048],\n",
       "         [ 1.6903, -0.8785, -2.3347],\n",
       "         [-0.5378,  0.7622, -1.2412],\n",
       "         [ 0.2852,  1.3993,  0.7797],\n",
       "         [ 1.6258,  0.4506, -0.6614],\n",
       "         [-0.4807,  1.0644, -0.6048],\n",
       "         [ 1.6903, -0.8785, -2.3347],\n",
       "         [-0.9651, -1.5319,  0.8214],\n",
       "         [-0.0761,  0.3362,  1.4899],\n",
       "         [ 1.6011,  0.2875,  0.1907],\n",
       "         [-0.8210,  1.0341,  2.3723],\n",
       "         [ 1.2841,  0.8247, -0.5056],\n",
       "         [ 0.2292,  1.5156, -0.1988],\n",
       "         [-0.2456, -0.6490,  1.1071],\n",
       "         [ 0.0639, -0.2898, -0.1037],\n",
       "         [ 0.2321,  2.0379,  1.3737]]),\n",
       " tensor([[ 0.0759,  0.1761, -0.5493],\n",
       "         [-0.6124,  0.5323, -1.2284],\n",
       "         [ 0.0125,  0.4428, -0.8751],\n",
       "         [-0.5447,  0.2373,  1.7358],\n",
       "         [-1.4266,  0.4551, -0.0601],\n",
       "         [-0.0516, -0.3702, -0.5804],\n",
       "         [-0.9651, -1.5319,  0.8214],\n",
       "         [-0.0761,  0.3362,  1.4899],\n",
       "         [ 1.6011,  0.2875,  0.1907],\n",
       "         [-0.8210,  1.0341,  2.3723],\n",
       "         [ 1.2841,  0.8247, -0.5056],\n",
       "         [ 0.2292,  1.5156, -0.1988],\n",
       "         [-0.2456, -0.6490,  1.1071],\n",
       "         [ 0.0639, -0.2898, -0.1037],\n",
       "         [ 0.2321,  2.0379,  1.3737]]),\n",
       " tensor([[ 0.0759,  0.1761, -0.5493],\n",
       "         [-0.6124,  0.5323, -1.2284],\n",
       "         [ 0.0125,  0.4428, -0.8751],\n",
       "         [-0.5447,  0.2373,  1.7358],\n",
       "         [-1.4266,  0.4551, -0.0601],\n",
       "         [-0.0516, -0.3702, -0.5804],\n",
       "         [-0.9651, -1.5319,  0.8214],\n",
       "         [-0.0761,  0.3362,  1.4899],\n",
       "         [ 1.6011,  0.2875,  0.1907],\n",
       "         [-0.8210,  1.0341,  2.3723],\n",
       "         [ 1.2841,  0.8247, -0.5056],\n",
       "         [ 0.2292,  1.5156, -0.1988],\n",
       "         [-0.2456, -0.6490,  1.1071],\n",
       "         [ 0.0639, -0.2898, -0.1037],\n",
       "         [ 0.2321,  2.0379,  1.3737]]),\n",
       " tensor([[ 0.0759,  0.1761, -0.5493],\n",
       "         [-0.6124,  0.5323, -1.2284],\n",
       "         [ 0.0125,  0.4428, -0.8751],\n",
       "         [-0.5447,  0.2373,  1.7358],\n",
       "         [-1.4266,  0.4551, -0.0601],\n",
       "         [-0.0516, -0.3702, -0.5804],\n",
       "         [-0.9651, -1.5319,  0.8214],\n",
       "         [-0.0761,  0.3362,  1.4899],\n",
       "         [ 1.6011,  0.2875,  0.1907],\n",
       "         [-0.8210,  1.0341,  2.3723],\n",
       "         [ 1.2841,  0.8247, -0.5056],\n",
       "         [ 0.2292,  1.5156, -0.1988],\n",
       "         [-0.2456, -0.6490,  1.1071],\n",
       "         [ 0.0639, -0.2898, -0.1037],\n",
       "         [ 0.2321,  2.0379,  1.3737]])]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_cache = Block_Cache(3)\n",
    "layers = 3\n",
    "query_status = torch.randn((2,3,30,3))\n",
    "key_cache = torch.randn((2,3,30,3))\n",
    "value_cache = torch.randn((2,3,20,3))\n",
    "position_modified_ids = adaptive_position(query_status,key_cache)\n",
    "for layer_idx in range(layers):\n",
    "    a = block_cache.update(layer_idx,query_status,key_cache,2)\n",
    "query_aware(\n",
    "    query_status=query_status,\n",
    "    key_cache=key_cache,\n",
    "    position_ids=torch.arange(30).reshape(1,-1).long(),\n",
    "    position_modified_ids= position_modified_ids,\n",
    "    value_cache=value_cache,\n",
    "    #layer_idx=0,\n",
    "    block_status = block_cache.block_cache[layer_idx],\n",
    "    block_dependency = block_cache.dependency_cache[layer_idx],\n",
    "    max_length = 100,\n",
    "    skip_num = 2,\n",
    "    find_num = 5,\n",
    "    position_method='origin'\n",
    "    \n",
    ")[1][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[[ 0.0000,  0.7484,  1.0772,  1.4092,  1.6217,  1.8003,  1.9236,\n",
       "             2.1574,  2.5313,  3.5135,  3.6902,  4.4828,  4.9626,  5.9117,\n",
       "             6.8460,  6.9550,  7.7628,  7.9340,  8.2262,  8.9921,  9.4382,\n",
       "             9.9781, 10.7287, 11.5100, 11.8646, 12.0024, 12.7541, 12.8277,\n",
       "            13.0167, 13.1253]],\n",
       " \n",
       "          [[ 0.0000,  0.2425,  1.0857,  1.5335,  2.2735,  3.0268,  3.6878,\n",
       "             3.8046,  4.6013,  5.2623,  5.7119,  5.9063,  6.2766,  6.4702,\n",
       "             6.8770,  7.0581,  7.1913,  7.2035,  7.7763,  8.7611,  8.9160,\n",
       "             9.7278,  9.9662, 10.5574, 10.8194, 11.3474, 11.4863, 11.5088,\n",
       "            12.3580, 12.9850]],\n",
       " \n",
       "          [[ 0.0000,  0.4564,  1.4409,  2.0489,  2.9918,  3.3788,  4.0007,\n",
       "             4.5170,  4.6228,  5.3165,  5.8892,  6.7288,  7.1764,  7.7302,\n",
       "             8.5494,  9.2882,  9.9641, 10.3002, 11.1738, 11.6385, 12.1458,\n",
       "            12.4396, 12.7708, 13.6429, 13.6493, 13.9483, 14.4054, 15.0909,\n",
       "            15.4665, 16.1269]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0000,  0.9716,  1.4799,  2.2651,  3.1490,  3.2896,  3.8333,\n",
       "             4.5539,  4.8380,  5.6421,  6.1604,  6.9795,  7.2938,  7.7557,\n",
       "             8.4416,  8.8714,  9.4787,  9.7694, 10.4055, 11.3763, 11.5736,\n",
       "            11.8204, 11.9785, 12.3424, 12.5116, 13.3737, 13.3742, 13.4127,\n",
       "            13.8727, 14.8592]],\n",
       " \n",
       "          [[ 0.0000,  0.3622,  1.0816,  1.3468,  1.3898,  2.1936,  2.7821,\n",
       "             3.1961,  3.5596,  3.9813,  4.6728,  4.9023,  5.0528,  5.6647,\n",
       "             6.2769,  6.6453,  7.2143,  7.2966,  7.7285,  8.1504,  8.8128,\n",
       "             8.8816,  9.2700,  9.8788, 10.7917, 11.6900, 12.3415, 12.7031,\n",
       "            13.5802, 13.8680]],\n",
       " \n",
       "          [[ 0.0000,  0.6999,  1.3105,  1.4923,  1.8974,  2.3915,  3.0158,\n",
       "             3.8763,  4.2249,  4.3534,  4.4885,  4.9152,  5.5449,  6.0181,\n",
       "             6.8501,  7.1704,  7.6279,  8.2313,  8.3459,  8.4898,  8.8436,\n",
       "             9.3993,  9.9850, 10.3909, 11.1624, 11.8598, 12.0352, 12.9365,\n",
       "            13.5889, 14.0760]]]]),\n",
       " tensor([[[[ 0.0000,  0.7484,  1.0772,  1.4092,  1.6217,  1.8003,  1.9236,\n",
       "             2.1574,  2.5313,  3.5135,  3.6902,  4.4828,  4.9626,  5.9117,\n",
       "             6.8460,  6.9550,  7.7628,  7.9340,  8.2262,  8.9921,  9.4382,\n",
       "             9.9781, 10.7287, 11.5100, 11.8646, 12.0024, 12.7541, 12.8277,\n",
       "            13.0167, 13.1253]],\n",
       " \n",
       "          [[ 0.0000,  0.2425,  1.0857,  1.5335,  2.2735,  3.0268,  3.6878,\n",
       "             3.8046,  4.6013,  5.2623,  5.7119,  5.9063,  6.2766,  6.4702,\n",
       "             6.8770,  7.0581,  7.1913,  7.2035,  7.7763,  8.7611,  8.9160,\n",
       "             9.7278,  9.9662, 10.5574, 10.8194, 11.3474, 11.4863, 11.5088,\n",
       "            12.3580, 12.9850]],\n",
       " \n",
       "          [[ 0.0000,  0.4564,  1.4409,  2.0489,  2.9918,  3.3788,  4.0007,\n",
       "             4.5170,  4.6228,  5.3165,  5.8892,  6.7288,  7.1764,  7.7302,\n",
       "             8.5494,  9.2882,  9.9641, 10.3002, 11.1738, 11.6385, 12.1458,\n",
       "            12.4396, 12.7708, 13.6429, 13.6493, 13.9483, 14.4054, 15.0909,\n",
       "            15.4665, 16.1269]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0000,  0.9716,  1.4799,  2.2651,  3.1490,  3.2896,  3.8333,\n",
       "             4.5539,  4.8380,  5.6421,  6.1604,  6.9795,  7.2938,  7.7557,\n",
       "             8.4416,  8.8714,  9.4787,  9.7694, 10.4055, 11.3763, 11.5736,\n",
       "            11.8204, 11.9785, 12.3424, 12.5116, 13.3737, 13.3742, 13.4127,\n",
       "            13.8727, 14.8592]],\n",
       " \n",
       "          [[ 0.0000,  0.3622,  1.0816,  1.3468,  1.3898,  2.1936,  2.7821,\n",
       "             3.1961,  3.5596,  3.9813,  4.6728,  4.9023,  5.0528,  5.6647,\n",
       "             6.2769,  6.6453,  7.2143,  7.2966,  7.7285,  8.1504,  8.8128,\n",
       "             8.8816,  9.2700,  9.8788, 10.7917, 11.6900, 12.3415, 12.7031,\n",
       "            13.5802, 13.8680]],\n",
       " \n",
       "          [[ 0.0000,  0.6999,  1.3105,  1.4923,  1.8974,  2.3915,  3.0158,\n",
       "             3.8763,  4.2249,  4.3534,  4.4885,  4.9152,  5.5449,  6.0181,\n",
       "             6.8501,  7.1704,  7.6279,  8.2313,  8.3459,  8.4898,  8.8436,\n",
       "             9.3993,  9.9850, 10.3909, 11.1624, 11.8598, 12.0352, 12.9365,\n",
       "            13.5889, 14.0760]]]]),\n",
       " tensor([[[[ 0.0000,  0.7484,  1.0772,  1.4092,  1.6217,  1.8003,  1.9236,\n",
       "             2.1574,  2.5313,  3.5135,  3.6902,  4.4828,  4.9626,  5.9117,\n",
       "             6.8460,  6.9550,  7.7628,  7.9340,  8.2262,  8.9921,  9.4382,\n",
       "             9.9781, 10.7287, 11.5100, 11.8646, 12.0024, 12.7541, 12.8277,\n",
       "            13.0167, 13.1253]],\n",
       " \n",
       "          [[ 0.0000,  0.2425,  1.0857,  1.5335,  2.2735,  3.0268,  3.6878,\n",
       "             3.8046,  4.6013,  5.2623,  5.7119,  5.9063,  6.2766,  6.4702,\n",
       "             6.8770,  7.0581,  7.1913,  7.2035,  7.7763,  8.7611,  8.9160,\n",
       "             9.7278,  9.9662, 10.5574, 10.8194, 11.3474, 11.4863, 11.5088,\n",
       "            12.3580, 12.9850]],\n",
       " \n",
       "          [[ 0.0000,  0.4564,  1.4409,  2.0489,  2.9918,  3.3788,  4.0007,\n",
       "             4.5170,  4.6228,  5.3165,  5.8892,  6.7288,  7.1764,  7.7302,\n",
       "             8.5494,  9.2882,  9.9641, 10.3002, 11.1738, 11.6385, 12.1458,\n",
       "            12.4396, 12.7708, 13.6429, 13.6493, 13.9483, 14.4054, 15.0909,\n",
       "            15.4665, 16.1269]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0000,  0.9716,  1.4799,  2.2651,  3.1490,  3.2896,  3.8333,\n",
       "             4.5539,  4.8380,  5.6421,  6.1604,  6.9795,  7.2938,  7.7557,\n",
       "             8.4416,  8.8714,  9.4787,  9.7694, 10.4055, 11.3763, 11.5736,\n",
       "            11.8204, 11.9785, 12.3424, 12.5116, 13.3737, 13.3742, 13.4127,\n",
       "            13.8727, 14.8592]],\n",
       " \n",
       "          [[ 0.0000,  0.3622,  1.0816,  1.3468,  1.3898,  2.1936,  2.7821,\n",
       "             3.1961,  3.5596,  3.9813,  4.6728,  4.9023,  5.0528,  5.6647,\n",
       "             6.2769,  6.6453,  7.2143,  7.2966,  7.7285,  8.1504,  8.8128,\n",
       "             8.8816,  9.2700,  9.8788, 10.7917, 11.6900, 12.3415, 12.7031,\n",
       "            13.5802, 13.8680]],\n",
       " \n",
       "          [[ 0.0000,  0.6999,  1.3105,  1.4923,  1.8974,  2.3915,  3.0158,\n",
       "             3.8763,  4.2249,  4.3534,  4.4885,  4.9152,  5.5449,  6.0181,\n",
       "             6.8501,  7.1704,  7.6279,  8.2313,  8.3459,  8.4898,  8.8436,\n",
       "             9.3993,  9.9850, 10.3909, 11.1624, 11.8598, 12.0352, 12.9365,\n",
       "            13.5889, 14.0760]]]])]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_cache.modified_position_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import warnings\n",
    "from typing import List, Optional, Tuple, Union\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.checkpoint\n",
    "from torch import nn\n",
    "from torch.nn import BCEWithLogitsLoss, CrossEntropyLoss, MSELoss\n",
    "\n",
    "from ...activations import ACT2FN\n",
    "from ...cache_utils import Cache, DynamicCache, StaticCache\n",
    "from ...modeling_outputs import (\n",
    "    BaseModelOutputWithPast,\n",
    "    CausalLMOutputWithPast,\n",
    "    QuestionAnsweringModelOutput,\n",
    "    SequenceClassifierOutputWithPast,\n",
    ")\n",
    "from ...modeling_utils import PreTrainedModel\n",
    "from ...pytorch_utils import ALL_LAYERNORM_LAYERS\n",
    "from ...utils import (\n",
    "    add_start_docstrings,\n",
    "    add_start_docstrings_to_model_forward,\n",
    "    is_flash_attn_2_available,\n",
    "    is_flash_attn_greater_or_equal_2_10,\n",
    "    logging,\n",
    "    replace_return_docstrings,\n",
    ")\n",
    "from .configuration_llama import LlamaConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(\n",
    "        self,\n",
    "        hidden_states: torch.Tensor,\n",
    "        attention_mask: Optional[torch.Tensor] = None,\n",
    "        position_ids: Optional[torch.LongTensor] = None, #输入的维度是[1, seseq_lengthgth]\n",
    "        past_key_value: Optional[Cache] = None,\n",
    "        block_cache: Optional[Block_Cache] = None,\n",
    "        output_attentions: bool = False,\n",
    "        use_cache: bool = False,\n",
    "        cache_position: Optional[torch.LongTensor] = None,\n",
    "        position_method = 'origin',\n",
    "        neighbor_block_num = 5,\n",
    "    ) -> Tuple[torch.Tensor, Optional[torch.Tensor], Optional[Tuple[torch.Tensor]]]:\n",
    "        batch_size, seq_length, hidden_dim = hidden_states.size()\n",
    "        \n",
    "\n",
    "        query_states = self.q_proj(hidden_states)\n",
    "        key_states = self.k_proj(hidden_states)\n",
    "        value_states = self.v_proj(hidden_states)\n",
    "        query_states = query_states.view(batch_size, seq_length, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        key_states = key_states.view(batch_size, seq_length, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
    "        value_states = value_states.view(batch_size, seq_length, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
    "\n",
    "\n",
    "        block_cache = getattr(self,\"block_cache\",block_cache)\n",
    "        past_key_value = getattr(self,\"past_key_value\", past_key_value)\n",
    "        \n",
    "\n",
    "        if past_key_value is not None:\n",
    "            key_states, value_states = past_key_value.update(key_states, value_states, self.layer_idx)\n",
    "        \n",
    "        modified_position_ids, block_states,block_dependency = block_cache.update(self.layer_idx,\n",
    "                                                                                  query_status = query_states,\n",
    "                                                                                  key_cache = key_states,\n",
    "                                                                                  neighbor_block_num = neighbor_block_num)\n",
    "        \n",
    "\n",
    "        \n",
    "        keys_to_be_used, values_to_be_used,position_to_be_used = query_aware(\n",
    "            query_status = query_states,\n",
    "            key_cache = key_states,\n",
    "            value_cache = value_states,\n",
    "            position_ids = position_ids,\n",
    "            position_modified_ids = modified_position_ids,\n",
    "            block_status = block_states,\n",
    "            block_dependency = block_dependency,\n",
    "            max_length = self.max_position_embeddings,\n",
    "            skip_num = neighbor_block_num,\n",
    "            find_num = neighbor_block_num,\n",
    "            position_method = position_method,\n",
    "            block_size = block_cache.block_size\n",
    "        )\n",
    "\n",
    "        cos, sin = self.rotary_emb(value_states, position_ids)\n",
    "        \n",
    "        #下一步要做的是针对每个query挑出来重要的blocks\n",
    "\n",
    "\n",
    "       \n",
    "        value_states = value_states.view(batch_size, seq_length, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
    "\n",
    "        past_key_value = getattr(self, \"past_key_value\", past_key_value)\n",
    "        cos, sin = self.rotary_emb(value_states, position_ids)\n",
    "        query_states, key_states = apply_rotary_pos_emb(query_states, key_states, cos, sin)\n",
    "\n",
    "        if past_key_value is not None:\n",
    "            # sin and cos are specific to RoPE models; position_ids needed for the static cache\n",
    "            cache_kwargs = {\"sin\": sin, \"cos\": cos, \"cache_position\": cache_position}\n",
    "            key_states, value_states = past_key_value.update(key_states, value_states, self.layer_idx, cache_kwargs)\n",
    "\n",
    "        key_states = repeat_kv(key_states, self.num_key_value_groups)\n",
    "        value_states = repeat_kv(value_states, self.num_key_value_groups)\n",
    "\n",
    "        attn_weights = torch.matmul(query_states, key_states.transpose(2, 3)) / math.sqrt(self.head_dim)\n",
    "\n",
    "        if attention_mask is not None:  # no matter the length, we just slice it\n",
    "            causal_mask = attention_mask\n",
    "            if cache_position is not None:\n",
    "                causal_mask = attention_mask[:, :, cache_position, : key_states.shape[-2]]\n",
    "            attn_weights = attn_weights + causal_mask\n",
    "\n",
    "        # upcast attention to fp32\n",
    "        attn_weights = nn.functional.softmax(attn_weights, dim=-1, dtype=torch.float32).to(query_states.dtype)\n",
    "        attn_weights = nn.functional.dropout(attn_weights, p=self.attention_dropout, training=self.training)\n",
    "        attn_output = torch.matmul(attn_weights, value_states)\n",
    "\n",
    "        if attn_output.size() != (batch_size, self.num_heads, seq_length, self.head_dim):\n",
    "            raise ValueError(\n",
    "                f\"`attn_output` should be of size {(batch_size, self.num_heads, seq_length, self.head_dim)}, but is\"\n",
    "                f\" {attn_output.size()}\"\n",
    "            )\n",
    "\n",
    "        attn_output = attn_output.transpose(1, 2).contiguous()\n",
    "\n",
    "        attn_output = attn_output.reshape(batch_size, seq_length, self.hidden_size)\n",
    "\n",
    "        if self.config.pretraining_tp > 1:\n",
    "            attn_output = attn_output.split(self.hidden_size // self.config.pretraining_tp, dim=2)\n",
    "            o_proj_slices = self.o_proj.weight.split(self.hidden_size // self.config.pretraining_tp, dim=1)\n",
    "            attn_output = sum([F.linear(attn_output[i], o_proj_slices[i]) for i in range(self.config.pretraining_tp)])\n",
    "        else:\n",
    "            attn_output = self.o_proj(attn_output)\n",
    "\n",
    "        if not output_attentions:\n",
    "            attn_weights = None\n",
    "\n",
    "        return attn_output, attn_weights, past_key_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
