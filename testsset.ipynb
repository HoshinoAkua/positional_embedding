{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mntcephfs/lab_data/hanyizhou/anaconda/pe/lib/python3.11/site-packages/torch/cuda/__init__.py:619: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/mntcephfs/lab_data/hanyizhou/anaconda/pe/lib/python3.11/site-packages/torch/cuda/__init__.py:749: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11060). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at /opt/conda/conda-bld/pytorch_1716905969073/work/c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() if nvml_count < 0 else nvml_count\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "import torch\n",
    "from gpt2_modified import *\n",
    "from datasets import load_dataset, load_from_disk\n",
    "from transformers import AutoTokenizer, TrainingArguments, GPT2Config, Trainer\n",
    "model_path = '/mntcephfs/data/ruoyusun/common_dirs/gpt2-small'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask'],\n",
       "    num_rows: 890793\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dataset = load_dataset('./dataset/testset/validationset')['train']\n",
    "dataset = load_from_disk('/mntcephfs/data/ruoyusun/hanyizhou/data/c4_512')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 制作50个句子, 其中每个句子长度都是用50个短句子拼接起来的."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 77.19it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "ds = {}\n",
    "for length in [512, 1024, 2048, 3072, 4096, 6144, 8192]:\n",
    "    ds[length] = []\n",
    "for i in tqdm(range(0,2500,50)): \n",
    "    data = sum(dataset[i:50+i]['input_ids'],[])\n",
    "    for length in [512, 1024, 2048, 3072, 4096, 6144, 8192]:\n",
    "        input_ids = data[:length]\n",
    "        ds[length].append(input_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8192"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ds[8192][10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ds中的数据结构为:\n",
    "\n",
    "\n",
    "length [512, 1024, 2048, 3072, 4096, 6144, 8192]\n",
    "\n",
    "\n",
    "list: sentence[0-49]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 制作三类模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#模型config设置\n",
    "config = GPT2Config()\n",
    "\n",
    "config.resid_pdrop = 0.0\n",
    "config.embd_pdrop = 0.0\n",
    "config.attn_pdrop = 0.0\n",
    "config.vocab_size = 50258"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fire = {}\n",
    "model_cope = {}\n",
    "model_mix = {}\n",
    "#model_change = {}\n",
    "for length in [512, 1024, 2048, 3072, 4096, 6144, 8192]:\n",
    "    config.n_positions = length\n",
    "    fire = GPT2_FIRE.from_pretrained('./output/fire/checkpoint-41250', config = config, ignore_mismatched_sizes=True)\n",
    "    fire.transformer.wpe = torch.nn.Embedding(length,768)\n",
    "    fire.transformer.wpe.weight = torch.nn.Parameter(torch.zeros(length,768))\n",
    "    cope = GPT2_CoPE.from_pretrained('./output/cope/checkpoint-41250', config = config, ignore_mismatched_sizes=True,n_posmax = 384)\n",
    "    mix = GPT2_FireWithCoPE.from_pretrained('./output/fire_with_cope/checkpoint-41250', config = config, ignore_mismatched_sizes=True)\n",
    "    cope.transformer.wpe = torch.nn.Embedding(length,768)\n",
    "    cope.transformer.wpe.weight = torch.nn.Parameter(torch.zeros(length,768))\n",
    "    mix.transformer.wpe = torch.nn.Embedding(length,768)\n",
    "    mix.transformer.wpe.weight = torch.nn.Parameter(torch.zeros(length,768))\n",
    "    change = mix\n",
    "    keys = fire.transformer._modules.keys()\n",
    "    for key in keys:\n",
    "        if key != 'h':\n",
    "            change.transformer._modules[key] = fire.transformer._modules[key]\n",
    "        else:\n",
    "            for i in range(12):\n",
    "                change.transformer.h[i].attn.c_attn = fire.transformer.h[i].attn.c_attn\n",
    "                change.transformer.h[i].attn.c_proj = fire.transformer.h[i].attn.c_proj\n",
    "                \n",
    "    change.lm_head = fire.lm_head\n",
    "    model_fire[length] = fire\n",
    "    model_cope[length] = cope\n",
    "    model_mix[length] = mix\n",
    "    model_change[length] = change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2_FireWithCoPE(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50258, 768)\n",
       "    (wpe): Embedding(512, 768)\n",
       "    (drop): Dropout(p=0.0, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block_FireWithCoPE(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention_FireWithCoPE(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (fire_with_cope): CoPEWithFIRE(\n",
       "            (input): Linear(in_features=1, out_features=32, bias=True)\n",
       "            (mlp_list): ModuleList(\n",
       "              (0-11): 12 x Sequential(\n",
       "                (0): Linear(in_features=1, out_features=32, bias=True)\n",
       "                (1): ReLU()\n",
       "                (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50258, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_change[512]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_fire, acc_cope, acc_mix = {}, {}, {}\n",
    "for length in [512, 1024, 2048, 3072, 4096, 6144, 8192]:\n",
    "    acc_fire[length] = []\n",
    "    acc_cope[length] = []\n",
    "    acc_mix[length] = []\n",
    "for length in tqdm([512, 1024, 2048, 3072, 4096, 6144, 8192]):\n",
    "    sequence_list = torch.tensor(ds[length])\n",
    "    fire = model_fire[length]\n",
    "    cope = model_cope[length]\n",
    "    mix = model_mix[length]\n",
    "    fire_output = fire(input_ids = sequence_list, labels = sequence_list)\n",
    "    cope_output = cope(input_ids = sequence_list, labels = sequence_list)\n",
    "    mix_output = mix(input_ids = sequence_list, labels = sequence_list)\n",
    "    acc_fire[length].append(fire_output.loss)\n",
    "    acc_cope[length].append(cope_output.loss)\n",
    "    acc_mix[length].append(mix_output.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_mix = np.load('./output/acc_mix.npy',allow_pickle=True).item()\n",
    "load_fire= np.load('./output/acc_fire.npy',allow_pickle=True).item()\n",
    "load_cope= np.load('./output/acc_cope.npy',allow_pickle=True).item()\n",
    "load_change = np.load('./output/acc_change.npy',allow_pickle=True).item()\n",
    "for key in load_mix.keys():\n",
    "    load_mix[key] = torch.tensor(load_mix[key]).mean().numpy()\n",
    "    load_fire[key] = torch.tensor(load_fire[key]).mean().numpy()\n",
    "    load_cope[key] = torch.tensor(load_cope[key]).mean().numpy()\n",
    "    load_change[key] = torch.tensor(load_change[key]).mean().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({512: array(11.366022, dtype=float32),\n",
       "  1024: array(11.8661, dtype=float32),\n",
       "  2048: array(12.179937, dtype=float32),\n",
       "  3072: array(12.306825, dtype=float32),\n",
       "  4096: array(12.414685, dtype=float32),\n",
       "  6144: array(12.526135, dtype=float32),\n",
       "  8192: array(12.590228, dtype=float32)},\n",
       " {512: array(11.366022, dtype=float32),\n",
       "  1024: array(11.8661, dtype=float32),\n",
       "  2048: array(12.179937, dtype=float32),\n",
       "  3072: array(12.306825, dtype=float32),\n",
       "  4096: array(12.414685, dtype=float32),\n",
       "  6144: array(12.526135, dtype=float32),\n",
       "  8192: array(12.590228, dtype=float32)},\n",
       " {512: array(3.4227178, dtype=float32),\n",
       "  1024: array(3.5610778, dtype=float32),\n",
       "  2048: array(3.641525, dtype=float32),\n",
       "  3072: array(3.7055151, dtype=float32),\n",
       "  4096: array(3.786891, dtype=float32),\n",
       "  6144: array(3.9346197, dtype=float32),\n",
       "  8192: array(4.0672827, dtype=float32)},\n",
       " {512: array(3.6817214, dtype=float32),\n",
       "  1024: array(3.8474314, dtype=float32),\n",
       "  2048: array(4.149472, dtype=float32),\n",
       "  3072: array(4.5055146, dtype=float32),\n",
       "  4096: array(4.891506, dtype=float32),\n",
       "  6144: array(5.5914974, dtype=float32),\n",
       "  8192: array(6.16001, dtype=float32)})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_change, load_mix, load_fire, load_cope"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
